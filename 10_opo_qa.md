---
layout: page
title: "OPOs and Quality Assurance and Performance Improvement Plans"
permalink: /Tissue-Donation
nav: true
weight: 1
toc: true
---

## Introduction {#introduction}

The Centers for Medicare and Medicaid Services (CMS) require all Organ
Procurement Organizations (OPOs) to produce Quality Assurance and Performance
Improvement (QAPI) plans. These plans are intended to be a “comprehensive,
data-driven [program] designed to monitor and evaluate performance of all
donation services,” and be used to “demonstrate performance improvement.”[^1]

While all OPOs are required to have QAPIs, the majority of OPOs still fail to
meet performance standards set by CMS, which calls the efficacy of QAPIs into
question. This report explores opportunities for CMS to dramatically strengthen
its QAPI process.

In practice, the use of QAPIs has historically been hampered by severe data
issues at OPOs, including a well-documented reliance on self-reporting, lack of
transparency, and lack of oversight by either CMS or the United Network for
Organ Sharing (UNOS), which currently operates as the Organ Procurement and
Transplant Network (OPTN) contractor.

However, QAPIs anchored in objective data and a transparent public accounting of
relative performance and quality of clinical care have the potential to drive
real performance improvement across the organ procurement system. The recent OPO
Final Rule creates an opportunity for CMS to make reforms to its QAPI process
and ensure they finally achieve their intended impact.

More specifically, with key measures included and proper oversight in place,
QAPIs could be used to hold OPOs accountable to higher performance standards,
leading to thousands more organs procured and transplanted—and lives saved—every
year.[^2]

## Current use of QAPIs {#current-use-of-qapis}

Since 2006, CMS has required that all OPOs create, annually review, and maintain
a QAPI program. The requirements for QAPI programs were revised under the
November 2020 Final Rule, which states that OPOs are expected to “implement a
comprehensive data-driven QAPI program to monitor and evaluate their
performance.”[^3]

Specifically, CMS currently reviews each QAPI to determine that the OPO:

1. Has comprehensive policies and procedures in place;
2. Monitors processes to ensure compliance with policies;
3. Tracks performance to ensure that improvements are sustained;
4. Reviews donor, family and/or staff complaints; and
5. Records minutes of meetings, committees, and formal QAPI activities.[^4] In
   practice, the mere existence of a QAPI is where the requirements stop. CMS
   provides guidance about the standard components of a QAPI[^5], but has not
   historically issued requirements for what specific metric definitions should
   be used in a QAPI, who should create the plan, or how specifically an OPO
   might use it to improve performance. Similarly, there is no process for CMS
   to evaluate the sufficiency of an individual OPO’s QAPI, or, relatedly,
   anyThere is no meaningful consequence for an OPO’s failure to adhere to its
   QAPI. **A former CMS staffer we spoke with told Bloom that QAPIs are “just
   paperwork [OPOs] have to do.” **

### The purpose of QAPIs {#the-purpose-of-qapis}

CMS’s goal should be for QAPIs to become public, data-driven improvement plans.
This goal is achievable now that CMS has finalized regulations to evaluate OPOs
based on objective data.

Specifically as it relates to QAPIs, the November 2020 Final Rule dictates that
OPOs must not rely “on any single source of information to conduct
self-assessments of their performance and should be employing a variety of
information as part of a comprehensive QAPI program.”[^6] This means OPOs will
be expected to include “a range of data and activities for this purpose that
will inform and drive performance.”[^7] It also introduces the opportunity for
improved measures
[based on the CMS “CALC” metric](#qapis-should-be-linked-to-calc).

OPO performance will be assessed annually based on revised donation and
transplantation outcome measures, with OPOs receiving a tier ranking established
by the lowest rates of the top 25% of OPOs.[^8] OPOs will be expected to review
these outcome measures as part of a QAPI, and must revise the QAPI if their
performance does not meet the performance threshold.

If an OPO cannot improve within the four-year certification cycle, it will be
decertified and the Designated Service Area (DSA) will be opened to competition
from other OPOs.

## QAPIs are not achieving their potential {#qapis-are-not-achieving-their-potential}

Despite these important steps towards QAPI improvements, Bloom heard from
experts that several issues hold back the implementation of many QAPIs,
including:

- **Lack of standardized data collection. **OPOs can use misleading and
  self-serving data measures, and can even create benchmarks and definitions
  that fit the existing data. The variation in data collection exacerbates
  existing opacity in OPO performance and operations, creating major challenges
  in accurately assessing OPO performance. For instance, if one OPO’s definition
  of “authorization” is unique to their organization, any associated QAPIs will
  not be able to be externally validated or benchmarked for improvement.
- **Lack of transparency. **Currently, OPOs are not required to make QAPI plans
  publicly available, and CMS does not publish detailed data on OPO
  performance.[^9] This means that major issues and areas for performance
  improvement are harder for researchers, media, patient advocates, hospitals,
  and other stakeholders to identify.

- **Lack of preparedness. **QAPIs can be a valuable way for OPOs to identify,
  prepare for, and respond to rapidly evolving and unexpected events, such as
  the COVID-19 pandemic. However, Bloom heard that OPOs do not maintain a strong
  culture of using QAPIs to prepare for changing circumstances and events.
- **Lack of accountability and consequences. **Consistently, experts we spoke
  with described a system where OPOs face almost no consequences for poor
  performance. Theoretically an OPO can be decertified by CMS, but this has
  never happened, despite severe performance failures and fatal lapses in
  patient safety.

To ensure high performance, the goal of a QAPI should be to help an OPO
understand its deficiencies and address them. However, as currently structured,
an OPO can meet the requirement of simply _having_ a QAPI without any broader
understanding of the importance or accuracy of the data being collected, or how
to use it to improve performance; this indicates that QAPIs are not set up to
achieve the intended purpose of helping OPOs continuously improve.

Bloom was told that OPOs can present their QAPI to a CMS auditor in a variety of
ways, because that there is no set standard for what a QAPI should look like.
This means that one OPO might develop a robust strategic plan, while another may
offer CMS a single spreadsheet listing generic goals. One OPO Executive reported
that an example OPO QAPI listed six goals, and every single one started with the
word “maintain.” Rather than being data-driven and quality-focused, the goals
this Executive saw were essentially made of “rainbows and butterflies.” Other
interviewees Bloom spoke with used words like “soft” and “fluffy” to describe
the work of OPO Quality Assurance Departments.

**With more than half of OPOs failing to meet tier one performance standards,
this means that at least half of all QAPIs are failing to result in sufficient
quality control and performance improvement.**

### Variation and data quality {#variation-and-data-quality}

Without a list of set measure definitions, it is up to each OPO to decide how to
collect and analyze the data included in the QAPI. Bloom heard several
interviewees talk about how OPOs can “pick and choose” how to include metrics by
creating definitions and benchmarks that fit existing data. **Variations in data
collection and quality create major downstream effects in developing an accurate
understanding of why OPOs are successful — or not. **Understanding such drivers
of OPO high- or poor-performance would help CMS oversee its OPO contractors, as
well as empirically inform future criteria for competition for OPO DSAs.

OPO executives themselves may not even realize that differing definitions can
hide a wide variety of practices across OPOs. OPO executives have different
standards for identifying potential donors, making decisions about when to
approach a family, having different relationships with hospitals driving (or
taking away from) referrals, and often provide varying oversight and guidance
for front line staff, all of which leads to distortions in data collection and
analysis. **Without clarity from CMS about how OPOs should define each measure
and use this data for QAPIs, these distortions remain opaque and difficult to
correct. **Furthermore, without knowing the specific processes used to collect
data, CMS cannot easily compare OPOs on specific process points, nor can CMS
ensure that OPOs are effectively and equitably serving all of their patient
communities.

**One major data issue is that OPOs have historically used inconsistent and
potentially misleading denominators to calculate metrics. **This is the
population figure used by OPOs to calculate measures like donor approach rate or
conversion rate.

For example, an OPO might claim they approached 280 out of 300 potential donors.
But if an underperforming OPO is not receiving every potential donor patient
referral possible because of its failure to develop a positive relationship with
a partner hospital, the real number of potential donor patients in the DSA will
not be reflected in the QAPI. It has been well-documented that OPOs may also
choose not to include certain categories of potential donor patients, which
often include older patients,[^10] rural patients,[^11] patients of color,[^12]
HIV+ patients,[^13] or medically-complex patients, despite the legal mandate
that OPOs must evaluate every patient referred to their care. Poor data
collection from the start creates inaccurate calculations and misleading
interpretation for every subsequent metric, masking poor performance and
inequitable care delivery.

One former CMS staffer confirmed that this is a rampant practice among OPOs.
OPOs “mis-report the denominator because they claim there are less potential
donor [patients]. If you don’t go out and identify potential donor [patients],
your success rate is higher because you only approached people who would consent
and be ‘good donors’…And so they don’t count in the denominator because they
weren’t considered potential donor [patients] — **if [the OPO] didn’t see it, it
didn’t happen**.” While CMS has corrected for misleading denominators in
performance measures via the 2020 OPO Final Rule, it must now also make
concomitant adjustments to its QAPI process to ensure that OPOs are held
accountable throughout the entirety of their contracts, rather just every four
years.[^14]

Additionally, if an OPO only counts the _incidence_ of an event, they may not
understand the _quality_ of that event. For instance, if an OPO only counts
whether a potential donor’s family authorized donation, they may not understand
the quality of that conversation or collect adequate feedback from the family or
hospital. Without the data to properly understand where they may be going wrong,
OPO executives are unlikely to meaningfully improve their family approaches.
This may help explain why, after controlling for increases in donors due to
factors outside of OPO influence, such as population growth and increased donors
resulting from the opioid and gun epidemics, OPOs have actually gotten _less_
effective over the past 10 years.[^15]

One reason that QAPI measures have been difficult to compare across OPOs is that
even measures that were internally reliable have not been valid across OPOs.
Without a valid measure for performance comparison, some OPO QAPIs have been
unable to connect care quality with performance outcomes. In the past, a QAPI
measure such as _percent onsite response within 60 minutes of hospital referral_
would have been anchored only to year-over-year data from the individual OPO,
without the ability to associate a threshold of compliance with the sample
measure with the OPO’s relative performance ranking. In other words, OPOs have
historically used internally consistent but externally invalid measures in their
QAPIs.

#### Consequences of inaccurate data {#consequences-of-inaccurate-data}

Bloom routinely heard from interviewees that OPOs don’t trust each other’s data,
making it difficult to identify accurate national or regional benchmarks for
their own performance and severely limiting the potential for sharing best
practices (the lack of valid measures for performance comparison is likely a
factor here). One OPO researcher Bloom spoke with identified this as a major
issue because it impacts CMS’s ability to understand shared practices among
OPOs. Currently, CMS cannot use QAPI data to identify shared practices between
all OPOs in the same tier, let alone compare rates at various points in the
procurement process before transplant.

Not being able to identify commonalities makes it easier for OPOs to claim
issues stem from a unique hospital or a unique population. Without a data-driven
understanding of best practices, an OPO may be truly unaware that their
practices fall outside of industry norms. This is compounded by the fact that
each hospital only works with one OPO, as the OPO holds a monopoly in the DSA.
For example, hospital staff may not be aware that the 50-hour case times of
their OPO are not normal, or anywhere close to the best practice. OPO
performance patterns have been examined across hospitals and hospital systems,
but at this time, such data is not commonly used by OPOs nor the OPTN contractor
to inform hospitals, regulators, or the public about identifiable patterns of
poor OPO practice.[^16]

### A lack of accountability allows OPOs to fail {#a-lack-of-accountability-allows-opos-to-fail}

While OPOs are required to maintain a QAPI and provide evidence to CMS that they
continually review this plan, such as sharing meeting minutes from a QAPI
review, in practice it is treated as a paperwork requirement and a box for CMS
auditors to check off. Several interviewees told Bloom that CMS auditors do not
have the training to fully understand what OPOs do, because they are the same
staff who audit sites with different procedures and standards, like blood banks.
One OPO consultant noted that much of their audit time was spent explaining to
the CMS auditor what OPOs actually do.

This creates a fundamental barrier to CMS providing accurate oversight.

Without in-depth training on OPO operations, CMS staff cannot be expected to
accurately audit an OPO’s performance or understand the components of a
successful QAPI. When asked why CMS does not invest more resources in OPO
performance and auditing, one former CMS staff member told Bloom that **organ
procurement “is small potatoes” for CMS, compared to the money CMS spends on
organizations like nursing homes and acute care facilities**. However, this
ignores not only the lives lost due to OPOs failures, but also the tremendous
downstream financial costs, which contribute to $36 billion/year in Medicare
expenditures on patients with end stage renal disease.[^17]

The urgency of reforms to strengthen CMS’s oversight of OPOs is further
compounded by the severe failures of other oversight bodies in the organ
donation industry. For example, the UNOS (which currently holds the contract for
the organ procurement transplantation network, OPTN) has consistently shown
itself to be reluctant to act, even when it is aware of potentially
life-threatening issues.[^18] Most alarmingly, in emails obtained by the Senate
Finance Committee, the UNOS’s then-CEO even joked that UNOS is “an overgrown
homeowners association;”[^19] UNOS’s Membership and Professional Standards
Committee (MPSC) recently came under scrutiny for failing to remediate fatal
patient safety lapses at OPOs.[^20]

#### The case of LiveOnNY {#the-case-of-liveonny}

The historical failures of CMS’s performance improvement plans have fatal
consequences. For example, LiveOnNY, the OPO for New York City, was threatened
with decertification twice in four years for severe performance failures, yet
still continues to operate.[^21]

Rather than decertify the OPO, however, CMS placed it on a “Performance
Improvement Plan,” while allowing it to continue to operate without any
functional consequences, including that the OPO’s CEO—despite a sustained record
of management failure—was allowed to remain in place. This plan was never made
public, nor was any empirically-supported rationale for which elements were and
were not included within it.

However, recent investigative reporting in The Markup “obtained [an] audit [of
LiveOn, which was part of the performance improvement plan], dated March 2019,
which found deep, systemic problems ranging from poor training and undefined
performance standards to a sweeping lack of urgency and missed donation
opportunities.”[^22]

The reporting also cited specific quotes from the audit, including that “One of
the most concerning trends that emerged during our assessment was the conscious
decision to allow LiveOnNY staff to leave cases where patients appeared brain
dead and the family was interested in organ donation” and that “There is a
history of hospitals expressing concern over service delivery from LiveOnNY”.

As noted in the Washington Post, CMS had placed the OPO on at least three
“corrective action plans” since 2012 . Despite such plans, over that period the
OPO “has consistently registered one of the poorest performances in the nation,”
and “ranked as the country’s second-worst OPO [in 2017].”[^23] In a July 2020
letter to Secretary Azar, Representatives Katie Porter and Karen Bass criticized
CMS’s reliance on performance improvement plans, writing that “patients do not
have years to wait,” and “there is no reason to have confidence that performance
improvement plans actually lead to OPO improvement or better results for
patients.”[^24]

These concerns proved to be well-founded. According to the most recent CMS data
available, as of 2020, LiveOn ranked 54th of 57 OPOs in the country,[^25] and
had one of the lowest rates of recovery of Black donors in the U.S.[^26]
Clearly, CMS’s performance improvement plans were ineffective, and must be
reformed to be anchored in objective data and transparency, and to carry
consequences if its objectives are not met. This would be in line with the way
many states use healthcare performance improvement plans and make them publicly
available.[^27] **OPOs are uniquely allowed to operate without an acceptable
level of transparency and accountability.**

## The future of QAPIs: Recommendations for action {#the-future-of-qapis-recommendations-for-action}

Under the November 2020 Final Rule, QAPIs must be revised when OPO performance
falls below the defined threshold. If an OPO cannot meet performance standards
for its next certification cycle, it risks losing the OPO’s existing DSA to a
higher performing OPO. **This makes data-driven QAPIs a vital part of OPO
operations moving forward.**

With key changes and updated metrics, QAPIs could be used to accurately evaluate
OPO performance and ensure that OPOs are held to standards that are truly
serving patients. For example, in collaboration with external researchers,
data-driven interventions at the Indiana Donor Network OPO created a 44%
increase in organ donors in just one year, driven by a 57% increase in the
number of potential donor families approached.[^28]

These significanthuge improvements were possible at an OPO that was ranked 51st
out 58 OPOs,[^29] suggesting that accurate data analysis and qualitative
performance improvement practices do have the ability to bring improvement to
even some of the lowest performing OPOs. Earlier research has highlighted that
this improvement was driven by heightened public scrutiny and oversight,
underscoring the importance of transparency in OPO performance data coupled with
systemic pressures to perform.[^30]

Moving forward, replicating turnarounds of failing OPOs through enforceable,
data-driven, public improvement plans is precisely what CMS’s goal should be for
QAPIs.

### Require accurate, standardized data collection {#require-accurate-standardized-data-collection}

A meaningful QAPI needs to be built on sound data. Without accurate,
standardized data, QAPIs are fundamentally not serving the OPO, let alone
hospitals and patients.

The first step in improving QAPIs is that **CMS must provide set definitions for
each process point and require standardized data measures** based on population
counts.

**Every single expert Bloom spoke with made this recommendation. **With a set
definition and an aggregated national number that can be broken down by OPO, CMS
staff and researchers would be able to clearly identify when attrition happens
and would be able to develop accurate comparisons between OPOs.

For a list of specific measures OPOs should be required to use, see
[Appendix A](#bookmark=id.wd1e4ydk35y).

### QAPIs should be linked to CALC {#qapis-should-be-linked-to-calc}

The new lever for more effective, more informative, and more accurate QAPIs is
the creation of a reliable, valid external measure of OPO performance: the CMS
metric, referred to as cause, age, and location-consistent (CALC) deaths. Using
CALC, OPOs can track the effectiveness of changes to clinical practice with
changes in objective performance ranking. This enables process and outcome QAPIs
to be both reliable and valid, creating opportunities for QAPIs to be used more
effectively and expansively than they have in the past.

Additionally, CALC offers regulators and OPOs the ability to construct QAPIs as
rates instead of counts. In the same way, regulators and OPOs now have the
ability to measure conversion and aspects of clinical care against rates of
donation-consistent deaths. Previously, OPO QAPIs were anchored to increases in
number, and did not appropriately account for changes in the number,
composition, and location of patient deaths within a service area.

Previously published research has established that the number of donors
recovered per 100 CALC deaths provides a reliable measure of OPO performance.
Critically, CALC-based performance measures are of equal discriminatory
power[^31] to those with much higher data reporting burdens, and provide
objective and reproducible data in a variety of population compositions.[^32]
Performance rates, measured as recovered donors and transplanted organs per 100
CALC deaths, also provide valuable context to other domains of transplantation,
such as differences in center-level organ import and utilization practices.[^33]

Several considerations support the use of a combination of internal,
OPO-reported process data measures and objective assessments of endpoint
(recovered donors, transplanted organs) performance using the CALC denominator.
First, peer-reviewed research has studied data already reported by OPOs to the
OPTN contractor.[^34] In this research, OPO-reported measures of activity at
individual hospitals were found to correlate with CALC-based assessments of
performance. Secondly, the CALC metric has shown sensitivity to changes in OPO
practice. In a separate peer-reviewed study,[^35] steady state and improved
performance of a single OPO, as measured using the CALC denominator, correlated
strongly with signals from OPO data on approaches and authorizations within
specific patient subgroups.

In the rulemaking period preceding the release of the 2021 CMS Final Rule, a
critique of the CALC data was that the source, Multiple Cause of Death (MCOD)
Data from the National Center for Health Statistics, reports information on a 12
to 16 month delay. Critics asserted that this made MCOD data ‘outdated’ at the
time of their release. In practice, this has been shown to be inconsequential,
as trends in area level deaths are generally gradual in nature and predictable
from other public health and demographic trends. Published evidence has shown
excellent fidelity with short term, seasonally-adjusted predictions of CALC
deaths at the level of OPOs’ base service populations, the Donor Service Area
(DSA).[^36] Short term area level predictions should allow practicable base
denominators on which to assess changes in overall OPO performance (donors
recovered and organs transplanted), and have sufficient reliability for QI
purposes in the absence of unanticipated changes to patterns of mortality. These
forecasts can provide near real term backstops to OPO internal process measures,
using correlation at a period of known (actual MCOD data) and forecast
denominators. Together, the combination of sources can produce a high level
assessment of performance trajectory and a more detailed depiction of areas of
strength and weakness in practice.

### QAPIs should be publicly available {#qapis-should-be-publicly-available}

In a system historically devoid of meaningful oversight, the lack of access to
QAPIs and their data is a glaring issue.[^37] **QAPIs should be made publicly
available. A community has the right to know how their healthcare providers are
failing them—particularly when those healthcare providers are funded by taxpayer
dollars.**

Numerous tools do exist for publicly evaluating and reviewing other types of
care providers, such as the
[Consumer Assessment of Healthcare Providers and Systems (CAHPS) survey](https://www.ahrq.gov/cahps/index.html)
that collects patient feedback. This survey is used to create detailed, publicly
available ratings of healthcare providers on
[Care Compare](https://www.medicare.gov/care-compare/), a CMS public
dashboard.[^38] **OPOs must be held to the same standard of transparency as any
other healthcare provider.**

### Ensure the right staff develop, have access to, and use the QAPI {#ensure-the-right-staff-develop-have-access-to-and-use-the-qapi}

An organizational culture of safety and performance improvement must start at
the top. OPO leadership must be engaged in creating and using the QAPI, and can
cultivate a culture of safety and performance improvement through key measures
such as:

- Maintaining a “transparent, non-punitive approach to reporting and learning
  from adverse events,” close calls, and near misses
- Seeing problems as organizational and operational, not as issues with
  individual employees
- Establishing a baseline performance measure on safety culture[^39]<sup>,
  </sup>[^40] Leadership must be held to performance improvement by an informed
  and engaged Board. This is a standard practice at hospitals, where Board
  reviews of leadership are based explicitly on safety and quality
  measures.[^41] Tools such as the World Management Survey Instrument have been
  used to assess hospital performance and safety practices, creating a baseline
  from which to improve.[^42]

**Additionally, every department at an OPO should be involved in creating the
QAPI**. An OPO will not be able to make sustainable improvements without
involving staff throughout the performance improvement process.

One OPO Executive Bloom spoke with meets with each of their department heads to
understand that department’s data and the resources they need to meet their
goals. Each department then creates its own QAPI, resulting in a 30-page
executive summary shared with the OPO leadership and Board. This QAPI is
reviewed in monthly meetings, with additional meetings to discuss strategic
planning. Given the dire necessity of their work, this is the level to which
OPOs should be held when creating and implementing a QAPI.

Not only should every department be engaged in creating the QAPI, but **every
staff member should have access to the plan (which should be public). **In order
for staff across an organization to have equitable access to data, the QAPI must
be developed and written in a way that is as accessible to entry-level employees
as it is to Board Members.

In addition to employees,** OPOs must be required to share the QAPI with
transplant centers and hospital partners.** Hospitals should see the same data
that an OPO sees. OPOs should not be allowed to manipulate process data to keep
key performance indicators opaque to hospital partners.

### QAPIs should incorporate patient feedback {#qapis-should-incorporate-patient-feedback}

With access to transparent, accessible data about OPO performance, patients and
their families will be able to make more informed decisions about working with
an OPO. In general, a community must be able to see how their OPO operates in
comparison to others, ultimately highlighting any areas of care disparity.
Research has consistently shown that OPOs fail to provide equitable services for
vulnerable populations, such as those who are rural, older, HIV+, or identified
as an historically underserved racial or ethnic group;[^43] transparent QAPI
data could allow researchers to better pinpoint these issues.[^44]

Additionally, if QAPIs incorporated patient and family feedback and were more
transparent, patients may have increased assurance that their complaints and
experiences are being heard. Currently, there is a strong selection bias within
OPO survey practices, as the patients and families who often remain involved
with an OPO do so because they had a positive experience. OPOs are not
adequately reaching and getting feedback from those families who did not consent
for donation or who had a poor experience. Yet these can be some of the most
vital experiences for identifying areas for performance improvements.

Currently, patients and families do have the option to register a complaint with
UNOS, though most families are unlikely to know this. Furthermore, UNOS’s
process for evaluating such complaints has a deeply questionable track record,
with the UNOS CEO himself characterizing the review process for complaints
related to patient care and safety as “like putting your kid's artwork up at
home. You value it because of how it was created rather than whether it's well
done. Only in this case, we persuade ourselves that it is well done
anyway.”[^45]

Overall, the process lacks the level of transparency that could help a patient
or family trust that their complaint is being addressed, and it is paramount
that CMS take meaningful actions to rectify this. Incorporating patient and
family feedback into a QAPI and making that QAPI public would go far to build
(or rebuild) trust with the very individuals OPOs are meant to serve.

### CMS should utilize QAPIs when evaluating competition {#cms-should-utilize-qapis-when-evaluating-competition}

QAPIs carry the potential to not only improve OPO performance and restore
patient trust in the system, but can also be used to strengthen other CMS
regulatory efforts related to OPOs, such as informing CMS’s criteria for
competition for OPO DSAs.

Specifically, under the 2020 Final Rule, CMS will be evaluating competition for
any DSA served by an underperforming OPO. CMS has estimated that between two and
five OPOs will apply for each DSA opened for competition.[^46] When evaluating
an OPO application, CMS should incorporate QAPIs as a marker of competitiveness.
An OPO should be required to submit its QAPI documents when applying for an open
DSA.

As an OPO Executive told Bloom, any OPO with a detailed strategic plan should be
able to clearly state its plans, staffing needs, expected donation and
transplant measures, and the estimated cost of this work. With a robust QAPI
program, these details should be already available.

CMS has improved system-wide performance through performance measures and QAPI
development models at the sector level before; skilled nursing facilities
patients and nursing home patients have both benefited from CMS strengthening
performance measures and defining priority areas for QAPIs, with widespread
adoption by organizations.[^47] In fact, recently published peer-reviewed
research from a nationally representative survey of more than 1,000 skilled
nursing facilities indicates that an average of 13 QI initiatives per
organization led to widespread, measurable improvements under CMS standards,
even for those facilities primarily serving rural and/or minority patients.[^48]

## Conclusion {#conclusion}

With the right regulations, review mechanisms, and standardized data in place,
QAPIs could be a valuable tool for effectively assessing OPOs and ensuring
performance improvement. When OPOs are held to rigorous standards, the organ
procurement system as a whole could see major improvements.

There is nothing unique about OPOs that means they should be allowed to operate
outside the standards of other healthcare providers. For decades, these
organizations have been underperforming with little to no consequence, while
causing thousands of preventable deaths each year, and disproportionately
harming patients of color.[^49]

As a 2022 bipartisan Senate Finance report concluded: “From the top down, the
U.S. transplant network is not working, putting Americans’ lives at risk.”[^50]
Patients and families have a right to know and understand what will happen to
themselves and their loved ones after death, while those waiting for a
transplant deserve transparency and accountability that they do not currently
have. OPOs must be held accountable for these patients and families.

#

# Appendix A: Recommended QAPI Data Points & Sources {#appendix-a-recommended-qapi-data-points-&-sources}

<table>
  <tr>
   <td><strong>Data Point</strong>
   </td>
   <td><strong>Source</strong>
   </td>
   <td><strong>Information Provided</strong>
   </td>
   <td><strong>Availability  (e.g., public, upon request, not public)</strong>
   </td>
  </tr>
  <tr>
   <td>Organ utilization: Organs recovered for transplant, transplanted by donation service area (DSA)
   </td>
   <td>Scientific Registry of Transplant Recipients
   </td>
   <td>Data on the number of organs, by type, that are authorized and successfully transplanted
   </td>
   <td>Public
   </td>
  </tr>
  <tr>
   <td>Number of recovered organ donors, by race/ethnicity (%) by donation service area (DSA)
   </td>
   <td>Scientific Registry of Transplant Recipients
   </td>
   <td>Data on the demographics of organ donor patients; provides insight for researchers tracking procurement and transplantation equity 
   </td>
   <td>Public, suppressed if &lt;10 patients annually within DSA
   </td>
  </tr>
  <tr>
   <td>Number of vented patients referred to OPO care stratified by demographic
   </td>
   <td>OPO, currently collected by OPTN contractor on the DNR
   </td>
   <td>Data on the demographics of potential organ donor patients; provides insight for researchers tracking procurement and transplantation equity, quality of care and access to care
<p>
Counts number of patient interactions for regulators
   </td>
   <td>Public, suppressed if &lt;10 patients annually within DSA
   </td>
  </tr>
  <tr>
   <td>Number of patients meeting referral criteria without appropriate hospital referral (adverse event)
   </td>
   <td>OPO, currently collected by OPTN contractor on the DNR
   </td>
   <td>Data on the demographics of potential organ donor patients; provides insight for researchers tracking procurement and transplantation equity , quality of care, access to care
<p>
Counts adverse events for regulators
   </td>
   <td>Not public at DSA level (small number of patients), should be public when aggregated at hospital system level/transplant system level
   </td>
  </tr>
  <tr>
   <td>Onsite patient evaluations (sometimes called “referral response”) rate
   </td>
   <td>OPO, currently collected at the organizational level but not reported to OPTN
   </td>
   <td>Provides insight for researchers tracking procurement and transplantation equity, quality of care, access to care
<p>
Provides quality of care data for regulators
   </td>
   <td>Public
   </td>
  </tr>
  <tr>
   <td>Onsite response to referred patient within 60 minutes
   </td>
   <td>OPO, currently collected at the organizational level but not reported to OPTN
   </td>
   <td>Provides insight for researchers tracking procurement and transplantation equity, quality of care, access to care
<p>
Provides quality of care data for regulators
<p>
Allows hospitals to validate OPO quality of care for patients referred
   </td>
   <td>Public
   </td>
  </tr>
  <tr>
   <td>Rate of referred patients per 100 CALC deaths (using seasonally-adjusted forecasts of CALC deaths)
   </td>
   <td>OPO, CMS denominator
   </td>
   <td>Provides insight for researchers tracking procurement and transplantation equity, quality of care, access to care
<p>
Provides quality of care data and measures effectiveness of OPO referral criteria for regulators
   </td>
   <td>Public
   </td>
  </tr>
  <tr>
   <td>Rate of referred patients ruled medically suitable
   </td>
   <td>OPO,  currently collected by OPTN contractor on the DNR
   </td>
   <td>Provides insight for researchers tracking procurement and transplantation equity, quality of care, access to care
<p>
Provides quality of care data and measures effectiveness of OPO referral criteria for regulators
   </td>
   <td>Public
   </td>
  </tr>
  <tr>
   <td>Rate of ruled medically suitable patients per 100 CALC deaths (using seasonally-adjusted forecasts of CALC deaths)
   </td>
   <td>OPO, CMS denominator
   </td>
   <td>Provides insight for researchers tracking procurement and transplantation equity, quality of care, access to care
<p>
Provides quality of care data and measures effectiveness of OPO referral criteria for regulators
   </td>
   <td>Public
   </td>
  </tr>
  <tr>
   <td>Rate of referred patients with approach (stratified by age, race/ethnicity, and OPTN cause of death)
   </td>
   <td>OPO, only authorization outcome is currently collected on the DNR (authorized yes/no), but all OPOs collect these data at the organizational level
   </td>
   <td>Provides insight for researchers tracking procurement and transplantation equity, quality of care, access to care
<p>
Provides quality of care data and effectiveness of selection for approach for regulators
<p>
Allows hospitals to validate OPO quality of care for patients referred
   </td>
   <td>Public, suppressed if &lt;10 patients annually within DSA
   </td>
  </tr>
  <tr>
   <td>Rate of family approach per 100 vented referrals
   </td>
   <td>OPOOPO, only authorization outcome is currently collected on the DNR (authorized yes/no), but all OPOs collect these data at the organizational level, CMS denominator
   </td>
   <td>Provides insight for researchers tracking procurement and transplantation equity, quality of care, access to care
<p>
Provides quality of care data and effectiveness of selection for approach for regulators
   </td>
   <td>Public
   </td>
  </tr>
  <tr>
   <td>Rate of family authorization per 100 approaches (stratified by age, race/ethnicity, and OPTN cause of death)
   </td>
   <td>OPO, only authorization outcome is currently collected on the DNR (authorized yes/no), but all OPOs collect these data at the organizational levelOPO
   </td>
   <td>Provides insight for researchers tracking procurement and transplantation equity, quality of care, access to care
<p>
Provides quality of care data and effectiveness of approach for regulators
<p>
Allows hospitals to validate OPO quality of care for patients referred
   </td>
   <td>Public
   </td>
  </tr>
  <tr>
   <td>Rate of “huddles” with hospital provider of all medically suitable patients
   </td>
   <td>OPO, all OPOs collect these data at the organizational levelOPO
   </td>
   <td>Provides insight for researchers tracking procurement and transplantation equity, quality of care, access to care, coordination of care
<p>
Provides quality of care data for regulators
<p>
Allows hospitals to validate OPO quality of care for patients referred
   </td>
   <td>Public
   </td>
  </tr>
  <tr>
   <td>Number of organs recovered by type
   </td>
   <td>OPTN (DDR), SRTR
   </td>
   <td>Data on the number of organs, by type, that are authorized and successfully transplanted
   </td>
   <td>Public
   </td>
  </tr>
  <tr>
   <td>Rate of recovered organs transplanted by type
   </td>
   <td>OPTN (DDR), SRTR
   </td>
   <td>Data on the number of organs, by type, that are authorized and successfully transplanted
   </td>
   <td>Public
   </td>
  </tr>
  <tr>
   <td>Rate of hospital compliance for appropriate referral of patients (i.e., number patients referred appropriately / number patients eligible to be referred per OPO death record review)
   </td>
   <td>OPTN, SRTR, OPO (available on the DNR, which currently characterizes timeliness, but does not describe compliance with clinical triggers)
   </td>
   <td>Provides insight for researchers tracking procurement and transplantation equity, quality of care, access to care, coordination of care
<p>
Provides quality of care, effectiveness of OPO referral criteria and associated data for regulators
<p>
Allows hospitals to validate OPO quality of care for patients referred
   </td>
   <td>Public
   </td>
  </tr>
  <tr>
   <td>Rate of family decline by category (stratified by age, race/ethnicity, and OPTN cause of death)
   </td>
   <td>OPO, only authorization outcome is currently collected on the DNR (authorized yes/no), but all OPOs collect these data at the organizational levelOPO
   </td>
   <td>Provides insight for researchers tracking procurement and transplantation equity, quality of care, access to care
<p>
Provides quality of care data and effectiveness of approach for regulators
<p>
Allows hospitals to validate OPO quality of care for patients referred
   </td>
   <td>Public, suppressed if &lt;10 patients annually within DSA
   </td>
  </tr>
  <tr>
   <td>Rate of potential donor patients authorized but not recovered
   </td>
   <td>OPO, DDR and DNR
   </td>
   <td>Provides insight for researchers tracking procurement and transplantation equity, quality of care, access to care
<p>
Provides quality of care data and effectiveness of donor management for regulators
   </td>
   <td>Public
   </td>
  </tr>
  <tr>
   <td>Rate of non-allocated organs by category for refusal
   </td>
   <td>OPO, OPTN
   </td>
   <td>Provides insight for researchers tracking procurement and transplantation equity, quality of care, access to care
<p>
Provides quality of care data and effectiveness of allocation and donor management for regulators
   </td>
   <td>Public
   </td>
  </tr>
  <tr>
   <td>Count of refusal codes associated with procurement adverse event 
   </td>
   <td>OPO, OPTN
   </td>
   <td>Provides insight for researchers tracking procurement and transplantation equity, quality of care, access to care
<p>
Provides quality of care data and effectiveness of allocation and donor management for regulators
   </td>
   <td>Upon request
   </td>
  </tr>
  <tr>
   <td>Rate of discarded organs of all recovered organs, by type  
   </td>
   <td>OPO, OPTN, DDR
   </td>
   <td>Provides insight for researchers tracking procurement and transplantation equity, quality of care, access to care
<p>
Provides quality of care data and effectiveness of allocation and donor management for regulators
   </td>
   <td>Public
   </td>
  </tr>
</table>

# Appendix B: Recommended QAPI Components

<table>
  <tr>
   <td><strong>Item</strong>
   </td>
   <td colspan="2" ><strong>Requirements</strong>
   </td>
   <td><strong>Department</strong>
   </td>
  </tr>
  <tr>
   <td colspan="4" ><strong>Organ Donation and Transplant Metrics</strong>
   </td>
  </tr>
  <tr>
   <td><strong>Process Data</strong>[^51]
   </td>
   <td colspan="2" ><em>For a complete list of recommended QAPI data points, see <a href="#bookmark=id.wd1e4ydk35y">Appendix A</a>.</em>
   </td>
   <td>Data must be collected across every OPO department. 
<p>
Quality Assurance Department compiles, analyzes, and ensures accuracy.
   </td>
  </tr>
  <tr>
   <td colspan="4" ><strong>Quality Assurance Department Reports</strong>
   </td>
  </tr>
  <tr>
   <td><strong>Safety Incident Review</strong>
   </td>
   <td colspan="2" ><em>In concert with Hospital and Family Services, Quality Assurance Department should prepare a report including: </em>
<ul>

<li>Review of any safety incidents that have been reported by hospital, transplant centers, or family partners[^52]

<li>Summary of responses made to any safety incident

<li>Updates to any previously reported safety incidents, including any new or updated protocols
</li>
</ul>
   </td>
   <td>Quality Assurance Department
<p>
Hospital and Family Services
   </td>
  </tr>
  <tr>
   <td><strong>Preparedness Statement</strong>
   </td>
   <td colspan="2" ><em>Working with every OPO department, Quality Assurance Department should prepare a report including: </em>
<ul>

<li>Current state of OPO preparedness in response to or during unexpected events, such as the COVID-19 pandemic[^53]

<li>Updates to any protocols made to increase preparedness
</li>
</ul>
   </td>
   <td>Quality Assurance Department
<p>
Department 
<p>
Leadership
   </td>
  </tr>
  <tr>
   <td><strong>Performance Improvement Projects</strong>
   </td>
   <td colspan="2" ><em>Quality Assurance Department should report on: </em>
<ul>

<li>Results of ongoing performance improvement projects

<li>Upcoming performance improvement projects 
<ul>
 
<li>Incorporate and highlight opportunities for staff review and comment[^54]
 
<li>Review process for developing and evaluating improvement projects; review criteria for determining priority.[^55] 
</li> 
</ul>

<li>Schedule of monthly QAPI review meetings[^56]
</li>
</ul>
   </td>
   <td>Quality Assurance Department
   </td>
  </tr>
  <tr>
   <td colspan="4" ><strong>Community</strong>
   </td>
  </tr>
  <tr>
   <td><strong>Registration and Outreach</strong>
   </td>
   <td colspan="2" ><em>Provide updates on: </em>
<ul>

<li>Current rates of community donor registration

<li>Details of upcoming outreach events

<li>Success of previous outreach events (eg., number of new donors registered)

<li>Details of ongoing outreach efforts and campaigns
</li>
</ul>
   </td>
   <td>Family Services, Hospital Services, Communications/Press Office
   </td>
  </tr>
  <tr>
   <td><strong>Patient and Family Feedback</strong>
   </td>
   <td colspan="2" ><em>OPO should provide updates and data gathered from ongoing surveys of donor families,</em>[^57]<em> covering key measures such as: </em>
<ul>

<li>The responsiveness, respect and courtesy shown by staff[^58]

<li>The speed and frequency with which families were able to get help and have questions answered

<li>How thoroughly staff explained the donation process[^59]

<li>How families felt about donation after the process was complete[^60]
</li>
</ul>
   </td>
   <td>Family Services
   </td>
  </tr>
  <tr>
   <td><strong>Hospital and Transplant Center Feedback</strong>
   </td>
   <td colspan="2" ><em>OPO should provide updates and data gathered from ongoing surveys of hospital and transplant center staff, covering key measures such as: </em>
<ul>

<li>The responsiveness, respect, and courtesy shown by staff

<li>Response times after a potential referral

<li>Effectiveness ratings of specific steps within the donation process (eg., donor evaluation, communication during referral)
</li>
</ul>
   </td>
   <td>Hospital Services
   </td>
  </tr>
  <tr>
   <td colspan="4" ><strong>Organization</strong>
   </td>
  </tr>
  <tr>
   <td><strong>Organizational Chart</strong>
   </td>
   <td colspan="2" ><em>Human Resources Department should provide: </em>
<ul>

<li>Organizational chart

<li>Summary of responsibilities for each department and/or key staff positions
</li>
</ul>
   </td>
   <td>Human Resources
   </td>
  </tr>
  <tr>
   <td><strong>Staff Training</strong>
   </td>
   <td colspan="2" ><em>Human Resources Department should provide: </em>
<ul>

<li>Upcoming and/or ongoing staff training opportunities and requirements

<li>Current state of staff training (i.e., number of staff in orientation, number of staff who have not met or renewed current training requirements)

<li>Review updated policies or protocols
</li>
</ul>
   </td>
   <td>Human Resources
   </td>
  </tr>
  <tr>
   <td><strong>Staff Feedback</strong>
   </td>
   <td colspan="2" ><em>Human Resources Department should provide:</em>
<p>
<em> </em>
<ul>

<li>Aggregated data from orientation and exit surveys
</li>
</ul>
   </td>
   <td>Human Resources
   </td>
  </tr>
  <tr>
   <td colspan="4" ><strong>Executive Summary</strong>
   </td>
  </tr>
  <tr>
   <td><strong>Strategic Planning Statement</strong>
   </td>
   <td colspan="2" >Strategic Planning Statement should reflect the current standing of the OPO according to CMS, future and current projects focused on improving organ donation and transplant, and future or current plans expansion (eg., competing for a neighboring DSA). 
   </td>
   <td>Executive
   </td>
  </tr>
  <tr>
   <td><strong>Financials</strong>
   </td>
   <td colspan="2" >Financial statement should reflect the current financial position of OPO and any details as required on publicly available tax documents, broken down by department. 
<p>
Financial statements should include a disclosure of  any potential conflicts of interest among Board Members and Executives. 
   </td>
   <td>Executive
   </td>
  </tr>
  <tr>
   <td colspan="4" ><strong>Definitions and Resources</strong>
   </td>
  </tr>
  <tr>
   <td>
   </td>
   <td colspan="2" >OPO should provide definitions and relevant details for all metrics included in QAPI. 
<p>
Provide staff and the public with commonly useful resources, like Scientific Registry of Transplant Recipients and links to CMS and OPTN guidelines and bylaws.
   </td>
   <td>Shared; Human Resources 
   </td>
  </tr>
  <tr>
   <td colspan="4" ><strong>Published Format</strong>
   </td>
  </tr>
  <tr>
   <td>
   </td>
   <td colspan="2" >OPO should make QAPI documents available to every staff member. OPOs must provide the most updated data available on a monthly basis.[^61] 
<p>
OPO should review QAPI at monthly staff meetings and quarterly Board meetings, and provide meeting minutes covering the QAPI review for CMS auditors. 
<p>
OPO must make QAPIs publicly available when they are submitted to CMS.[^62]  
   </td>
   <td>Communications
   </td>
  </tr>
</table>

<!-- Footnotes themselves at the bottom. -->

## Notes

[^1]:
    [“§ 486.348 Condition: Quality assessment and performance improvement (QAPI).”](https://www.law.cornell.edu/cfr/text/42/486.348)
    Centers for Medicare and Medicaid, 2020.

[^2]:
    [“A System in Need of Repair: Addressing Organizational Failures of the U.S.’s Organ Procurement and Transplantation Network.”](<https://www.finance.senate.gov/imo/media/doc/UNOS%20Hearing%20Confidential%20Memo%20(FOR%20RELEASE).pdf>)
    United States Senate, 2020.

[^3]:
    [“Medicare and Medicaid Programs; Organ Procurement Organizations Conditions for Coverage: Revisions to the Outcome Measure Requirements for Organ Procurement Organizations.”](https://www.govinfo.gov/content/pkg/FR-2020-12-02/pdf/2020-26329.pdf)
    Department of Health and Human Services, Federal Register, December 2020.

[^4]:
    [“New Organ Procurement Organization (OPO) Survey Protocol and Guidance Revisions in Appendix Y of the State Operations Manual (SOM).”](https://www.cms.gov/Medicare/Provider-Enrollment-and-Certification/SurveyCertificationGenInfo/Downloads/QSO18-23-OPO.pdf)
    Department of Health and Human Services, Center for Clinical Standards and
    Quality/Quality, Safety & Oversight Group, 2018.

[^5]:
    [“§ 486.348 Condition: Quality assessment and performance improvement (QAPI).”](https://www.law.cornell.edu/cfr/text/42/486.348)
    Centers for Medicare and Medicaid, 2020.

[^6]:
    [“Medicare and Medicaid Programs; Organ Procurement Organizations Conditions for Coverage: Revisions to the Outcome Measure Requirements for Organ Procurement Organizations.”](https://www.govinfo.gov/content/pkg/FR-2020-12-02/pdf/2020-26329.pdf)
    Department of Health and Human Services, Federal Register, December 2020.

[^7]:
    [“Medicare and Medicaid Programs; Organ Procurement Organizations Conditions for Coverage: Revisions to the Outcome Measure Requirements for Organ Procurement Organizations.”](https://www.govinfo.gov/content/pkg/FR-2020-12-02/pdf/2020-26329.pdf)
    Department of Health and Human Services, Federal Register, December 2020.

[^8]:
    [“Organ Procurement Organization (OPO) Conditions for Coverage Final Rule: Revisions to Outcome Measures for OPOs CMS-3380-F.”](https://www.cms.gov/newsroom/fact-sheets/organ-procurement-organization-opo-conditions-coverage-final-rule-revisions-outcome-measures-opos#:~:text=On%20November%2020%2C%202020%2C%20the,receive%20Medicare%20and%20Medicaid%20payment.)
    Centers for Medicare and Medicaid, November 2020.

[^9]:
    Under the Final Rule, CMS will publish a tiered ranking of OPO performance,
    with tiers established by the lowest performance of the top 25% of OPOs.

[^10]:
    [“Results of a data-driven performance improvement initiative in organ donation.” ](https://onlinelibrary.wiley.com/doi/full/10.1111/ajt.16442)
    \_American Journal of Transplantation, \_2020.

[^11]:
    [“Procurement characteristics of high- and low-performing OPOs as seen in OPTN/SRTR data,”](https://onlinelibrary.wiley.com/doi/10.1111/ajt.16832)
    \_American Journal of Transplantation, \_2021.

[^12]:
    [“Rejecting bias: The case against race adjustment for OPO performance in communities of color,”](https://pubmed.ncbi.nlm.nih.gov/32185873/)
    _American Journal of Transplantation_, 2020.

[^13]:
    [“Potential donor characteristics and decisions made by organ procurement organization staff: Results of a discrete choice experiment,”](https://pubmed.ncbi.nlm.nih.gov/34463013/)
    _Transplant Infectious Disease_, 2021;
    [“Barriers experienced by organ procurement organizations in implementing the HOPE act and HIV-positive organ donation,”](https://pubmed.ncbi.nlm.nih.gov/34180726/)
    _AIDS Care_, 2022.

[^14]:
    Per the 2020 OPO Final Rule, OPOs are evaluated on 4-year contract cycles,
    and only performance failures in the 4th year of any contracting cycle can
    merit decertification.

[^15]:
    [ “Not all organ donation increases equal OPO improvement,”](https://bloomworks.digital/organdonationreform/assets/PDF/donation-increase.pdf)
    Bloomworks, 2020.

[^16]:
    [“Procurement characteristics of high- and low-performing OPOs as seen in OPTN/SRTR data,”](https://onlinelibrary.wiley.com/doi/10.1111/ajt.16832)
    \_American Journal of Transplantation, \_2021.

[^17]:
    Graphic:
    [Organ Procurement Money Flow](https://bloomworks.digital/organdonationreform/Appendix/#organ-procurement-money-flow-pdf),
    Bloomworks, 2020.

[^18]:
    [“Transplant monitor lax in oversight.”](https://www.latimes.com/news/la-me-transplant22oct22-story.html)
    _LA Times_, 2006.

[^19]:
    [“Hearing Memo: A System in Need of Repair: Addressing Organizational Failures of the U.S.’s Organ Procurement and Transplantation Network,”](<https://www.finance.senate.gov/imo/media/doc/UNOS%20Hearing%20Confidential%20Memo%20(FOR%20RELEASE).pdf>)
    United States Senate, 2020.

[^20]:
    [“70 deaths, many wasted organs are blamed on transplant system errors.”](https://www.washingtonpost.com/health/2022/08/03/transplant-deaths-mistakes-senate-finance/)
    _Washington Post, 2022._

[^21]:
    [Letter from Senator Todd Young to the Honorable Seema Verda, Administrator for Centers for Medicare & Medicaid Services](http://young.senate.gov/imo/media/doc/190417%20-%20Letter%20to%20CMS%20Re%20OPO%20Metrics.pdf), 2019.

[^22]:
[^23]:
    [“New York’s organ collection agency, nation’s second-largest, threatened with closure.”](https://www.washingtonpost.com/national/health-science/new-york-organ-collection-agency-nations-second-largest-threatened-with-closure/2018/07/11/09c52824-847b-11e8-8f6c-46cb43e3f306_story.html)
    \_Washington Post, \_2018.

[^24]:
    [“Letter to the Honorable Alex Azar, Secretary, and the Honorable Seema Verma, Administrator.”](https://porter.house.gov/sites/porter.house.gov/files/porter%20letter%20to%20hhs%20cms%20re%20opos.pdf)
    Representatives Katie Porter and Karen Bass, 2020.

[^25]:
    Data via [CMS](https://qcor.cms.gov/main.jsp), visualized at OPOdata.org.
    See [“LiveOn NY (NYRT),”](https://opodata.org/opo/NYRT) Bloomworks, 2020.

[^26]:
    Data from 2019 (most recent publicly available).
    “[Organ donation recovery rates worse for people of color, data show](https://www.axios.com/2021/11/09/organ-donation-recovery-worse-people-of-color).”
    _Axios_, 2021. Note: LiveOn experienced a change in leadership in 2021; data
    for 2021 will be released in spring 2022.

[^27]:
    [“Performance Improvement Plan - Mass General Brigham.”](https://www.mass.gov/service-details/performance-improvement-plan-mass-general-brigham)
    Massachusetts Health Policy Commission, 2022.

[^28]:
    [“Results of a data-driven performance improvement initiative in organ donation.” ](https://onlinelibrary.wiley.com/doi/full/10.1111/ajt.16442)
    \_American Journal of Transplantation, \_2020.

[^29]:
    Note:
    [Two OPOs merged on January 1, 2021](https://unos.org/news/lifechoice-donor-services-and-new-england-organ-bank-to-merge-jan-1/?gclid=Cj0KCQjw-fmZBhDtARIsAH6H8qiFUr5wNjAY_jFy5ZT3ABSSspZnEqE4jk2liu7_3VLJfMdy89c6qSsaAp4xEALw_wcB),
    so there are now 57 OPOs. However, at the time of the Indiana Donor Network
    intervention, there were 58 OPOs.

[^30]:
    [ “Oversight Gaps and Conflicts,”](https://bloomworks.digital/organdonationreform/Oversight/)
    Bloomworks, 2020;
    [“Public discourse and policy change: Absence of harm from increased oversight and transparency in OPO performance,”](https://pubmed.ncbi.nlm.nih.gov/33565252/)
    \_American Journal of Transplantation, \_2021.

[^31]:
    [“Addressing Critiques of the Proposed CMS Metric of Organ Procurement Organ Performance: More Data Isn't Better,”](https://pubmed.ncbi.nlm.nih.gov/32732845/)
    _Transplantation_, 2020.

[^32]:
    [“Rejecting bias: The case against race adjustment for OPO performance in communities of color,”](https://pubmed.ncbi.nlm.nih.gov/32185873/)
    _American Journal of Transplantation_, 2020.

[^33]:
    [“Examining utilization of kidneys as a function of procurement performance,”](https://pubmed.ncbi.nlm.nih.gov/35118830/)
    _American Journal of Transplantation_, 2022.

[^34]:
    [“Procurement characteristics of high- and low-performing OPOs as seen in OPTN/SRTR data,”](https://onlinelibrary.wiley.com/doi/10.1111/ajt.16832)
    \_American Journal of Transplantation, \_2021.

[^35]:
    [“Results of a data-driven performance improvement initiative in organ donation.” ](https://onlinelibrary.wiley.com/doi/full/10.1111/ajt.16442)
    \_American Journal of Transplantation, \_2020.

[^36]:
    [“Public discourse and policy change: Absence of harm from increased oversight and transparency in OPO performance,”](https://pubmed.ncbi.nlm.nih.gov/33565252/)
    \_American Journal of Transplantation, \_2021.

[^37]:
    See: “Current Reliance on Media for Accountability,” in
    [“Oversight Gaps and Conflicts.”](https://bloomworks.digital/organdonationreform/Oversight/)
    Bloomworks, 2020.

[^38]:
    For additional examples, see: [HEDIS Measures](https://www.ncqa.org/hedis/)
    (National Committee for Quality Assurance);
    [Leapfrog Ratings](https://www.leapfroggroup.org/ratings-reports/how-our-ratings-are-used)
    (The Leapfrog Group).

[^39]:
    The Joint Commission has recommended tools such as:
    [Surveys on Patient Safety Culture](https://www.ahrq.gov/sops/surveys/index.html)
    (Agency for Healthcare Research and Quality) and
    [Safety Attitudes and Safety Climate Questionnaire](https://www.uth.edu/chqs/safety-survey)
    (Center for Healthcare Quality and Safety)

[^40]:
    For additional information on developing a culture of safety, see:
    [“The essential role of leadership in developing a safety culture.”](https://www.jointcommission.org/-/media/tjc/documents/resources/patient-safety-topics/sentinel-event/sea-57-safety-culture-and-leadership-final2.pdf)
    The Joint Commission, 2017.

[^41]:
    [“Leadership Role in Improving Safety.”](https://psnet.ahrq.gov/primer/leadership-role-improving-safety)
    Agency for Healthcare Research and Quality, 2019.

[^42]:
    [“Hospital Board And Management Practices Are Strongly Related To Hospital Performance On Clinical Quality Metrics.”](https://www.healthaffairs.org/doi/10.1377/hlthaff.2014.1282)
    _Health Affairs_, 2015.

[^43]:
    [“Results of a data-driven performance improvement initiative in organ donation.”](https://onlinelibrary.wiley.com/doi/full/10.1111/ajt.16442)<span style="text-decoration:underline;">
    </span> _American Journal of Transplantation, \_2020;
    [“Procurement characteristics of high- and low-performing OPOs as seen in OPTN/SRTR data,”](https://onlinelibrary.wiley.com/doi/10.1111/ajt.16832)
    \_American Journal of Transplantation, \_2021;
    [“Rejecting bias: The case against race adjustment for OPO performance in communities of color,”](https://pubmed.ncbi.nlm.nih.gov/32185873/)
    \_American Journal of Transplantation_, 2020;
    [“Potential donor characteristics and decisions made by organ procurement organization staff: Results of a discrete choice experiment,”](https://pubmed.ncbi.nlm.nih.gov/34463013/)
    _Transplant Infectious Disease_, 2021;
    [“Barriers experienced by organ procurement organizations in implementing the HOPE act and HIV-positive organ donation,”](https://pubmed.ncbi.nlm.nih.gov/34180726/)
    _AIDS Care_, 2022.

[^44]:
    [“Inequity in Organ Donation.”](https://bloomworks.digital/organdonationreform/Inequity/)
    Bloomworks, 2020.

[^45]:
    [“Hearing Memo: A System in Need of Repair: Addressing Organizational Failures of the U.S.’s Organ Procurement and Transplantation Network.”](<https://www.finance.senate.gov/imo/media/doc/UNOS%20Hearing%20Confidential%20Memo%20(FOR%20RELEASE).pdf>)
    United States Senate, 2020.

[^46]:
    [“The Lowdown on Organ Procurement Organizations.”](https://www.natlawreview.com/article/episode-18-low-down-organ-procurement-organizations-podcast)
    _National Law Review_, 2021.

[^47]:
    [CMS.gov: QAPI Description and Background](https://www.cms.gov/Medicare/Provider-Enrollment-and-Certification/QAPI/qapidefinition);
    [“Taking a Look at Systematic Quality Improvement Using the Five QAPI Elements,”](https://cmscompliancegroup.com/2012/05/01/1-qapi-systematic-improvement/)
    CMS Compliance Group, 2012.

[^48]:
    [“Nursing Home Responses to Performance-based Accountability: Results of a National Survey,”](https://pubmed.ncbi.nlm.nih.gov/32379920/)
    _Journal of the American Geriatrics Society_, 2020.

[^49]:
    For data on preventable deaths, see: [OPOdata.org](https://opodata.org/).
    Bloomworks, 2022.

[^50]:
    UNOS Hearing Confidential Memo (PDF for release):
    [“A System in Need of Repair: Addressing Organizational Failures of the U.S.’s Organ Procurement and Transplantation Network,”](<https://www.finance.senate.gov/imo/media/doc/UNOS%20Hearing%20Confidential%20Memo%20(FOR%20RELEASE).pdf>) 2020.

[^51]:

<p>
     For further details on some of these recommended metrics, see: <a href="https://optn.transplant.hrsa.gov/media/3015/201906_spc_boardreport.pdf">“Ad Hoc Systems Performance Committee Report.”</a> OPTN, 2019.

[^52]:

<p>
     Cases should be summarized anonymously. If OPO policies preclude sharing this information publicly, then OPO should provide aggregated data as to the incidence of specific types of safety reports. OPO must still provide information as to the responses taken and any newly updated protocols.

[^53]:

<p>
     Preparedness measures could include: steps taken to physically protect facilities during extreme weather events; updated pandemic-specific measures; community investments made to support families and transplant recipients during times of economic hardship (eg., increased funding for transplant family accommodations during economic recession); responses to updated clinical guidelines or new regulations from CMS or OPTN.

[^54]:

<p>
     Quality Assurance Department must actively solicit staff input, especially when determining the priority level of a given performance improvement project.

[^55]:

<p>
     For a QAPI process model, see: <a href="https://pubmed.ncbi.nlm.nih.gov/16985402/">“Meeting the Center for Medicare & Medicaid Services Requirements for Quality Assessment and Performance Improvement: A Model for Hospitals.”</a> <em>Journal of Nursing Care Quality</em>, 2006.

[^56]:

<p>
     Ideally, staff from every department should be present at QAPI review meetings. Additionally, OPOs should provide an alternate mechanism for collecting ongoing staff feedback, such as surveys or report sharing from departmental meetings.

[^57]:

<p>
     These surveys must be available to both families who consented for donation and those who did not.

[^58]:

<p>
     This measure should include any staff position a family or patient interacts with. For example, in the <a href="https://www.hcahpsonline.org/globalassets/hcahps/quality-assurance/2022_survey-instruments_english_mail.pdf">HCAHPS</a> survey for hospital care, interactions with nurses and doctors are rated separately.

[^59]:

<p>
     It is crucial that families provide informed consent and fully understand the donation process. OPOs should collect a rating about the degree to which families felt they understood the consent process.

[^60]:

<p>
     Measures like how likely a family is to remain involved with the OPO (eg., through volunteer work) can be an additional indicator of the overall quality of their experience.

[^61]:

<p>
     Some measures, such as national rankings, may not be updated monthly. OPOs should provide the most recent data, in lieu of monthly updates, where appropriate.

[^62]:

<p>
     Like an Annual Report, a QAPI must be made public at least once annually. Previous QAPI documents should be available for review upon request.
